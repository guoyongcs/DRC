#### general settings
name: search_DCLSx4_drc_setting2
use_tb_logger: false
model: blind
distortion: sr
scale: 4
gpu_ids: [0]
pca_matrix_path: ../../../pca_matrix/DCLS/pca_aniso_matrix_x4.pth
dual_weight: 0.1

degradation:
  random_kernel: True
  ksize: 31
  code_length: 10
  sig_min: 0.6
  sig_max: 5
  rate_iso: 0
  random_disturb: true

#### datasets
datasets:
  train:
    name: DIV2K
    mode: GT
    dataroot_GT: /data_root/dataset/sr/DF2K.lmdb

    use_shuffle: true
    n_workers: 8  # per GPU
    batch_size: 16
    GT_size: 256
    LR_size: 64
    use_flip: true
    use_rot: true
    color: RGB
    data_range: 1-800
    subset_ratio: 1.0
  val:
    name: DIV2KRK
    mode: LQGT
    dataroot_GT: /data_root/dataset/sr/DIV2KRK/gt
    dataroot_LQ: /data_root/dataset/sr/DIV2KRK/lr_x4
    data_range: 1-5

#### network structures
network_G:
  which_model_G: DCLS
  setting:
    nf: 64
    nb: 10
    ng: 5
    input_para: 256
    kernel_size: 31
    dual: true

#### path
path:
  pretrain_model_G: ../../../../DCLS/model_zoo/DCLSx4_setting2.pth # It is possible to directly use the original pretrained model of DCLS that does not has the dual model, because the dual model is easy to be learned.
  strict_load: false
  resume_state: ~

#### training settings: learning rate scheme, loss
train:
  lr_G: !!float 1e-5
  lr_E: !!float 1e-5
  lr_scheme: MultiStepLR
  beta1: 0.9
  beta2: 0.99
  niter: 500000
  warmup_iter: -1  # no warm up
  lr_steps: [200000, 400000]
  lr_gamma: 0.5
  eta_min: !!float 1e-7

  pixel_criterion: l1
  pixel_weight: 1.0

  manual_seed: 0
  val_freq: !!float 2e3

#### search settings:
search:
  pruning_rate: 0.3                         # pruning rate, 0.3, 0.5 or 0.7
  alpha_lr: !!float 3e-4                    #learning rate
  alpha_weight_decay: !!float 1e-3                  # weight decay for alpha
  w_weight_decay: 0                         # weight decay, default 0
  w_momentum: 0.9                           # SGD momentum, default 0.9
  w_grad_clip: 5.0                # gradient clipping for weights
  unordered_channels: false       # indicate whether sort channels during searching, default setting false
  resume_search: null             # resume pruning from specific checkpoint
  search_epochs: 100              # the number of epochs for searching the structure of the model
  print_every: 5                  # how many batches to wait before logging training status

#### logger
logger:
  print_freq: 1
  save_checkpoint_freq: !!float 2e3
