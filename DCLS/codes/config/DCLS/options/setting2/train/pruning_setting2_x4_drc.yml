#### general settings
name: pruning_DCLSx4_drc_setting2
use_tb_logger: true
model: blind
distortion: sr
scale: 4
gpu_ids: [0]
pca_matrix_path: ../../../pca_matrix/DCLS/pca_aniso_matrix_x4.pth
dual_weight: 0.1

degradation:
  random_kernel: True
  ksize: 31
  code_length: 10
  sig_min: 0.6
  sig_max: 5
  rate_iso: 0
  random_disturb: true

#### datasets
datasets:
  train:
    name: DIV2K
    mode: GT
    dataroot_GT: /data_root/dataset/sr/DIV2K/DIV2K_train_HR/

    use_shuffle: true
    n_workers: 8  # per GPU
    batch_size: 16
    GT_size: 256
    LR_size: 64
    use_flip: true
    use_rot: true
    color: RGB
    data_range: 1-800
    subset_ratio: 0.2
  val:
    name: DIV2KRK
    mode: LQGT
    dataroot_GT: /data_root/home/dengzeshuai/data/sr/DIV2KRK/gt_rename
    dataroot_LQ: /data_root/home/dengzeshuai/data/sr/DIV2KRK/lr_x4
    data_range: 1-5

#### network structures
network_G:
  which_model_G: DCLS
  setting:
    nf: 64
    nb: 10
    ng: 5
    input_para: 256
    kernel_size: 31
    dual: true

#### path
path:
  pretrain_model_G: ~/pretrained_models/DCLS-SR/DCLSx4_setting2.pth # It is possible to directly use the original pretrained model of DCLS that does not has the dual model, because the dual model is easy to be learned.
  strict_load: false
  resume_state: ~

#### training settings: learning rate scheme, loss
train:
  lr_G: !!float 1e-5
  lr_E: !!float 1e-5
  lr_scheme: MultiStepLR
  beta1: 0.9
  beta2: 0.99
  niter: 500000
  warmup_iter: -1  # no warm up
  lr_steps: [200000, 400000]
  lr_gamma: 0.5
  eta_min: !!float 1e-7

  pixel_criterion: l1
  pixel_weight: 1.0

  manual_seed: 0
  val_freq: !!float 2e3

#### pruning settings:
pruning:
  pruning_rate: 0.3                       # pruning rate, 0.3, 0.5 or 0.7
  configs_path: ../../../model_zoo/DCLS_prune03.txt                        # path to the configs of the number of channels in each layer
  layer_wise_lr: !!float 1e-5             #learning rate
  weight_decay: 0                         # weight decay, default 0
  momentum: 0.9                           # SGD momentum, default 0.9
  resume_pruning: ~                       # resume pruning from specific checkpoint
  prune_type: dcp                         # prune type, dcp|cp|thinet

#### logger
logger:
  print_freq: 20
  save_checkpoint_freq: !!float 2e3
