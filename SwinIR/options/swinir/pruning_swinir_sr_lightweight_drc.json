{
  "task": "prune_swinir_sr_lightweight_drn_x4"     //  classical image sr for x2/x3/x4. root/task/images-models-options
  , "model": "plain" // "plain" | "plain2" if two inputs
  , "gpu_ids": [0, 1]
  , "dist": false 
  , "warmup_steps": 0 

  ,"scale": 4       // 2 | 3 | 4
  , "n_channels": 3  // broadcast to "datasets", 1 for grayscale, 3 for color

  , "path": {
    "root": "superresolution"            // "denoising" | "superresolution" | "dejpeg"
    , "save_dir": "../experiment/0_SwinIR_experiments/pruned_p70_swinir_light_drn/" // path to save experimental results
    , "pretrained_netG": "../SwinIR/model_zoo/model_to_be_pruned.pth"   // It is better to use the pretrained model with DR, i.e., SwinIR-light-DR. Indeed, it is also possible to directly use the original pretrained model of SwinIR-light that does not has the dual model, because the dual model is easy to be learned.
    , "pretrained_netE": null      // path of pretrained model
  }

  , "datasets": {
    "train": {
      "name": "train_dataset"           // just name
      , "dataset_type": "sr"         // "dncnn" | "dnpatch" | "fdncnn" | "ffdnet" | "sr" | "srmd" | "dpsr" | "plain" | "plainpatch" | "jpeg"
      , "dataroot_H": "/data_root/dataset/sr/DIV2K/DIV2K_train_HR/"// path of H training dataset. DIV2K (800 training images)
      , "dataroot_L": "/data_root/dataset/sr/DIV2K/DIV2K_train_LR_bicubic/X4/"              // path of L training dataset

      , "H_size": 256                   // 128/192/256/512.
      , "data_range": "1-800"             // train data range of DIV2K
      , "subset_ratio": 0.2             //  use subset of data, using 160 images by default  
      , "dataloader_shuffle": true
      , "dataloader_num_workers": 16     //
      , "dataloader_batch_size": 16      // Total batch size =8x8=64 in SwinIR
    }
    , "test": {
      "name": "test_dataset"            // just name
      , "dataset_type": "sr"         // "dncnn" | "dnpatch" | "fdncnn" | "ffdnet" | "sr" | "srmd" | "dpsr" | "plain" | "plainpatch" | "jpeg"
      , "dataroot_H": "/data_root/dataset/sr/benchmark/Set5/HR/"  // path of H testing dataset
      , "dataroot_L": "/data_root/dataset/sr/benchmark/Set5/LR_bicubic/X4/"              // path of L testing dataset

    }
  }

  , "netG": {
    "net_type": "swinir_pruned" 
    , "upscale": 4                      // 2 | 3  | 4
    , "in_chans": 3 
    , "img_size": 64
    , "window_size": 8  
    , "img_range": 1.0 
    , "depths": [6, 6, 6, 6]
    , "embed_dim": 60 
    , "num_heads": [6, 6, 6, 6]
    , "mlp_ratio": 2 
    , "upsampler": "pixelshuffledirect"        // "pixelshuffle" | "pixelshuffledirect" | "nearest+conv" | null
    , "resi_connection": "1conv"        // "1conv" | "3conv"
    , "dual": true        // true | false
    , "init_type": "default"
    , "config_path": null // path to the config files of the dimentional of features
  }

  , "train": {
    "G_lossfn_type": "l1"               // "l1" preferred | "l2sum" | "l2" | "ssim" | "charbonnier"
    , "G_lossfn_weight": 1.0            // default
    , "dual_weight": 0.1                // weight for dual loss

    , "E_decay": 0.999                  // Exponential Moving Average for netG: set 0 to disable; default setting 0.999

    , "G_optimizer_type": "adam"        // fixed, adam is enough
    , "G_optimizer_lr": 2e-4            // learning rate
    , "G_optimizer_wd": 0               // weight decay, default 0
    , "G_optimizer_clipgrad": null      // unused
    , "G_optimizer_reuse": true         // 

    , "G_scheduler_type": "MultiStepLR" // "MultiStepLR" is enough
    , "G_scheduler_milestones": [250000, 400000, 450000, 475000, 500000]
    , "G_scheduler_gamma": 0.5

    , "G_regularizer_orthstep": null    // unused
    , "G_regularizer_clipstep": null    // unused

    , "G_param_strict": false 
    , "E_param_strict": false 

    , "checkpoint_test": 5000           // for testing
    , "checkpoint_save": 5000           // for saving model
    , "checkpoint_print": 10           // for print
  }

  , "pruning": {
    "pruning_rate" : 0.3              // pruning rate, 0.3, 0.5 or 0.7
    , "configs_path": "model_zoo/swinir/swinir_light_drc_channel_config.txt"            // path to the configs of the number of channels in each layer
    , "layer_wise_lr": 1e-4            // learning rate
    , "weight_decay": 0              // weight decay, default 0
    , "momentum": 0.9                // SGD momentum, default 0.9
    //, "warm_start" : true           // init pruned layer weight using origin layer
    , "resume_pruning": null        // resume pruning from specific checkpoint
    , "prune_type" : "dcp"          // prune type, dcp|cp|thinet
  }
}
